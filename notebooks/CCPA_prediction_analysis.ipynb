{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffeffce3-423b-4fe1-bfed-ba0ec6144d7d",
   "metadata": {},
   "source": [
    "**Requirements:**\n",
    "* Trained models\n",
    "\n",
    "**Outputs:** \n",
    "* none \n",
    "___\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0202ee-03ec-4495-8c86-fbd0b51a3640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch[10:41:50] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /home/icb/leon.hetzel/miniconda3/envs/chemical_CPA/lib/python3.7/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.1.so: cannot open shared object file: No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import umap.plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sn\n",
    "\n",
    "from utils import load_config, load_dataset, load_smiles, load_model, compute_drug_embeddings, compute_pred\n",
    "from compert.data import load_dataset_splits\n",
    "\n",
    "matplotlib.style.use(\"fivethirtyeight\")\n",
    "matplotlib.style.use(\"seaborn-talk\")\n",
    "matplotlib.rcParams['font.family'] = \"monospace\"\n",
    "matplotlib.rcParams['figure.dpi'] = 60\n",
    "matplotlib.pyplot.rcParams['savefig.facecolor'] = 'white'\n",
    "sn.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a4c8e9e-00d0-4c9c-b676-17dd904f33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2595fa-425f-43f4-94e2-27d95282cfd7",
   "metadata": {},
   "source": [
    "# Load and analyse model \n",
    "* Define `seml_collection` and `model_hash` to load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0582a055-1b72-45d1-afe7-98033e0e8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "seml_collection = \"finetuning_num_genes\"\n",
    "\n",
    "# split_ho_pathway, append_ae_layer: true\n",
    "model_hash_pretrained = \"70290e4f42ac4cb19246fafa0b75ccb6\" # \"config.model.load_pretrained\": true, \n",
    "model_hash_scratch = \"ed3bc586a5fcfe3c4dbb0157cd67d0d9\" # \"config.model.load_pretrained\": false, \n",
    "\n",
    "# split_ood_finetuning, append_ae_layer: true\n",
    "model_hash_pretrained = \"bd001c8d557edffe9df9e6bf09dc4120\" # \"config.model.load_pretrained\": true, \n",
    "model_hash_scratch = \"6e9d00880375aa450a8e5de60250659f\" # \"config.model.load_pretrained\": false, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca9c7b-806f-43bb-ae50-9e79345323d9",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24e760f-7d62-42b3-bb64-9a2b125622fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1f1237f9c54142800c21294fe8348b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b7ddf8f24f4735814bccb77bd856ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = load_config(seml_collection, model_hash_pretrained)\n",
    "dataset, key_dict = load_dataset(config)\n",
    "config['dataset']['n_vars'] = dataset.n_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3951653-2787-4e7e-ad15-d926ebe0972c",
   "metadata": {},
   "source": [
    "### Load smiles info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc51c43-7f1e-4e28-b4c3-871cf2ca6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "canon_smiles_unique_sorted, smiles_to_pathway_map, smiles_to_drug_map = load_smiles(config, dataset, key_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c3855-54dd-4646-a6fe-e10b737c9f57",
   "metadata": {},
   "source": [
    "#### Define which drugs should be annotaded with list `ood_drugs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0580fc-9cdf-4202-9078-7ceaaf510519",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_drugs = dataset.obs.condition[dataset.obs[config[\"dataset\"][\"data_params\"][\"split_key\"]].isin(['ood'])].unique().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e21e1-2e26-4a64-b99d-ef4243df1212",
   "metadata": {},
   "source": [
    "#### Get pathway level 2 annotation for clustering of drug embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a278306f-dd5b-4dde-901d-ad8ed1730107",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_to_pw_level2_map = {}\n",
    "pw1_to_pw2 = {}\n",
    "\n",
    "for (drug, pw1, pw2), df in dataset.obs.groupby(['SMILES', 'pathway_level_1', 'pathway_level_2']): \n",
    "    smiles_to_pw_level2_map[drug] = pw2\n",
    "    if pw1 in pw1_to_pw2:\n",
    "        pw1_to_pw2[pw1].add(pw2)\n",
    "    else: \n",
    "        pw1_to_pw2[pw1] = {pw2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de36423-0181-4189-95e0-07028d0bb7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DNA methylation',\n",
       " 'Histone methylation',\n",
       " 'Bromodomain',\n",
       " 'Histone demethylase',\n",
       " 'Histone deacetylation',\n",
       " 'Histone acetylation']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = [\"Epigenetic regulation\"]\n",
    "\n",
    "groups_pw2 = [pw2 for pw in groups for pw2 in pw1_to_pw2[pw]]\n",
    "groups_pw2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb3703-5e1c-4e66-b146-50dc44b0b470",
   "metadata": {},
   "source": [
    "## Load dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44664d2c-e615-4d43-a69d-33ae5a74ac7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covariate_keys': 'cell_type',\n",
       " 'dataset_path': '/storage/groups/ml01/projects/2021_chemicalCPA_leon.hetzel/datasets/sciplex_complete.h5ad',\n",
       " 'degs_key': 'all_DEGs',\n",
       " 'dose_key': 'dose',\n",
       " 'pert_category': 'cov_drug_dose_name',\n",
       " 'perturbation_key': 'condition',\n",
       " 'smiles_key': 'SMILES',\n",
       " 'split_key': 'split_ood_finetuning',\n",
       " 'use_drugs_idx': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['data_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6ce86c-6ecb-4165-9f60-a17617503770",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = config['dataset']['data_params']\n",
    "\n",
    "# #Overwrite split_key \n",
    "# data_params['split_key'] = 'split_ho_epigenetic'\n",
    "\n",
    "datasets = load_dataset_splits(**data_params, return_dataset=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fa33c5-41c5-4d1c-a9b3-efd9a69657a7",
   "metadata": {},
   "source": [
    "___\n",
    "## Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c966e60-eeab-4749-abdf-2d821e9a05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dosages = [1e1, 1e2, 1e3, 1e4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "886d036b-23f6-4b23-84cc-197735881f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe62dea173da498bb4436452f39fa262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89618e7e3c99409387208dd664673b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = load_config(seml_collection, model_hash_pretrained)\n",
    "config['dataset']['n_vars'] = dataset.n_vars\n",
    "model_pretrained, embedding_pretrained = load_model(config, canon_smiles_unique_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db01530-d598-4a91-a2b0-f1b2c444e48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c93f780cd2a48a8893bbafa50727e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCF7_CUDC-101_0.001: 0.82\n",
      "MCF7_CUDC-101_0.01: 0.83\n",
      "MCF7_CUDC-101_0.1: 0.82\n",
      "MCF7_CUDC-101_1.0: 0.63\n",
      "MCF7_CUDC-907_0.001: 0.70\n",
      "MCF7_CUDC-907_0.01: 0.71\n",
      "MCF7_CUDC-907_0.1: 0.61\n",
      "MCF7_CUDC-907_1.0: -0.39\n",
      "MCF7_Dacinostat_0.001: 0.72\n",
      "MCF7_Dacinostat_0.01: 0.72\n",
      "MCF7_Dacinostat_0.1: 0.13\n",
      "MCF7_Dacinostat_1.0: -0.09\n",
      "MCF7_Givinostat_0.001: 0.76\n",
      "MCF7_Givinostat_0.01: 0.77\n",
      "MCF7_Givinostat_0.1: 0.84\n",
      "MCF7_Givinostat_1.0: -0.22\n",
      "MCF7_Hesperadin_0.001: 0.78\n",
      "MCF7_Hesperadin_0.01: 0.80\n",
      "MCF7_Hesperadin_0.1: 0.87\n",
      "MCF7_Hesperadin_1.0: 0.80\n",
      "MCF7_Pirarubicin_0.001: 0.68\n",
      "MCF7_Pirarubicin_0.01: 0.69\n",
      "MCF7_Pirarubicin_0.1: 0.69\n",
      "MCF7_Pirarubicin_1.0: 0.64\n",
      "MCF7_Raltitrexed_0.001: 0.70\n",
      "MCF7_Raltitrexed_0.01: 0.68\n",
      "MCF7_Raltitrexed_0.1: 0.66\n",
      "MCF7_Raltitrexed_1.0: 0.66\n",
      "MCF7_Tanespimycin_0.001: 0.73\n",
      "MCF7_Tanespimycin_0.01: 0.67\n",
      "MCF7_Tanespimycin_0.1: 0.64\n",
      "MCF7_Tanespimycin_1.0: 0.59\n",
      "MCF7_Trametinib_0.001: 0.72\n",
      "MCF7_Trametinib_0.01: 0.72\n",
      "MCF7_Trametinib_0.1: 0.74\n",
      "MCF7_Trametinib_1.0: 0.75\n"
     ]
    }
   ],
   "source": [
    "drug_r2_pretrained, _ = compute_pred(model_pretrained, \n",
    "                                     datasets['ood'], \n",
    "                                     genes_control=datasets['test_control'].genes, \n",
    "                                     dosages=dosages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95edee6a-44f8-4225-89c7-0102a656d1b4",
   "metadata": {},
   "source": [
    "## Non-pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59afd9cd-74f0-468d-8a90-a115e22af6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf74012abba047718fcdfbfc564799f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4377cfc01792426e9bfcbf12cca27ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = load_config(seml_collection, model_hash_scratch)\n",
    "config['dataset']['n_vars'] = dataset.n_vars\n",
    "model_scratch, embedding_scratch = load_model(config, canon_smiles_unique_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ab2c27d-1044-4c30-b1fd-ab63ada6423b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d917571b86c2485a83c29e85671e6fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCF7_CUDC-101_0.001: 0.56\n",
      "MCF7_CUDC-101_0.01: 0.55\n",
      "MCF7_CUDC-101_0.1: 0.50\n",
      "MCF7_CUDC-101_1.0: 0.24\n",
      "MCF7_CUDC-907_0.001: 0.35\n",
      "MCF7_CUDC-907_0.01: 0.33\n",
      "MCF7_CUDC-907_0.1: 0.16\n",
      "MCF7_CUDC-907_1.0: -0.39\n",
      "MCF7_Dacinostat_0.001: 0.38\n",
      "MCF7_Dacinostat_0.01: 0.27\n",
      "MCF7_Dacinostat_0.1: -0.29\n",
      "MCF7_Dacinostat_1.0: -0.41\n",
      "MCF7_Givinostat_0.001: 0.45\n",
      "MCF7_Givinostat_0.01: 0.46\n",
      "MCF7_Givinostat_0.1: 0.14\n",
      "MCF7_Givinostat_1.0: -0.49\n",
      "MCF7_Hesperadin_0.001: 0.47\n",
      "MCF7_Hesperadin_0.01: 0.48\n",
      "MCF7_Hesperadin_0.1: 0.16\n",
      "MCF7_Hesperadin_1.0: 0.39\n",
      "MCF7_Pirarubicin_0.001: 0.40\n",
      "MCF7_Pirarubicin_0.01: 0.40\n",
      "MCF7_Pirarubicin_0.1: 0.44\n",
      "MCF7_Pirarubicin_1.0: 0.32\n",
      "MCF7_Raltitrexed_0.001: 0.35\n",
      "MCF7_Raltitrexed_0.01: 0.34\n",
      "MCF7_Raltitrexed_0.1: 0.23\n",
      "MCF7_Raltitrexed_1.0: 0.25\n",
      "MCF7_Tanespimycin_0.001: 0.21\n",
      "MCF7_Tanespimycin_0.01: 0.22\n",
      "MCF7_Tanespimycin_0.1: 0.33\n",
      "MCF7_Tanespimycin_1.0: 0.22\n",
      "MCF7_Trametinib_0.001: 0.05\n",
      "MCF7_Trametinib_0.01: -0.02\n",
      "MCF7_Trametinib_0.1: 0.26\n",
      "MCF7_Trametinib_1.0: 0.29\n"
     ]
    }
   ],
   "source": [
    "drug_r2_scratch, _ = compute_pred(model_scratch,\n",
    "                                  datasets['ood'],\n",
    "                                  genes_control=datasets['test_control'].genes, \n",
    "                                  dosages=dosages) # non-pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84a0b518-02bb-4286-8c17-cd2e393d956d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Raltitrexed',\n",
       " 'Trametinib',\n",
       " 'Hesperadin',\n",
       " 'CUDC-101',\n",
       " 'Dacinostat',\n",
       " 'Pirarubicin',\n",
       " 'CUDC-907',\n",
       " 'Tanespimycin',\n",
       " 'Givinostat']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.obs.loc[dataset.obs.split_ood_finetuning=='ood', 'condition'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ce533c2-eef2-4bf3-90a7-3351a747e753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19084201256434122"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([max(v, 0) for v in drug_r2_scratch.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "503ca154-4d11-4de8-9615-f400edc26bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45148704449335736"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([max(v, 0) for v in drug_r2_pretrained.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d257733-e80b-4d96-ab4f-e20ecc5ecd1a",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62f75dbe-6687-45a8-bb8b-af2f9d5e13b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model_saved\": \"test.pt\"}\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import json\n",
    "\n",
    "file_name = \"test.pt\"\n",
    "torch.save(\n",
    "            (\n",
    "                model_scratch.state_dict(),\n",
    "                # adversary covariates are saved as a list attr on the autoencoder\n",
    "                # which PyTorch doesn't include in the autoencoder's state dict\n",
    "                [\n",
    "                    adversary_covariates.state_dict()\n",
    "                    for adversary_covariates in model_scratch.adversary_covariates\n",
    "                ],\n",
    "#                 TODO I haven't checked that this actually works\n",
    "                [\n",
    "                  covariate_embedding.state_dict()\n",
    "                  for covariate_embedding in model_scratch.covariates_embeddings\n",
    "                ],\n",
    "                model_scratch.init_args,\n",
    "                model_scratch.history,\n",
    "            ),\n",
    "            file_name,\n",
    "        )\n",
    "pjson = lambda s: print(json.dumps(s), flush=True)\n",
    "pjson({\"model_saved\": file_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75baa9dd-ec88-43ec-952b-3fbc237d7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_torch_model(file_path, append_ae_layer=False): \n",
    "    dumped_model = torch.load(file_path)\n",
    "    if len(dumped_model) == 3:\n",
    "        # old version\n",
    "        state_dict, model_config, history = dumped_model\n",
    "    else:\n",
    "        # new version\n",
    "        assert len(dumped_model) == 5\n",
    "        (\n",
    "            state_dict,\n",
    "            adversary_cov_state_dicts,\n",
    "            cov_embeddings_state_dicts,\n",
    "            model_config,\n",
    "            history,\n",
    "        ) = dumped_model\n",
    "        assert len(cov_embeddings_state_dicts) == 1\n",
    "        print(\"hi\")\n",
    "#     # sanity check\n",
    "#     if append_ae_layer:\n",
    "#         assert model_config[\"num_genes\"] < self.datasets[\"training\"].num_genes\n",
    "#     else:\n",
    "#         assert model_config[\"num_genes\"] == self.datasets[\"training\"].num_genes\n",
    "#     assert model_config[\"use_drugs_idx\"]\n",
    "#     keys = list(state_dict.keys())\n",
    "#     for key in keys:\n",
    "#         # remove all components which we will train from scratch\n",
    "#         # the drug embedding is saved in the state_dict for some reason, but we don't need it\n",
    "#         if key.startswith(\"adversary_drugs\") or key == \"drug_embeddings.weight\":\n",
    "#             state_dict.pop(key)\n",
    "#     if self.embedding_model_type == \"vanilla\":\n",
    "#         # for Vanilla CPA, we also train the amortized doser & drug_embedding_encoder anew\n",
    "#         keys = list(state_dict.keys())\n",
    "#         for key in keys:\n",
    "#             if key.startswith(\"dosers\") or key.startswith(\"drug_embedding_encoder\"):\n",
    "#                 state_dict.pop(key)\n",
    "    return state_dict, cov_embeddings_state_dicts, model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "478056a1-33ce-420b-81ae-b2e6ad62866a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0595, -1.1332, -1.0637,  ..., -0.1452, -0.4641,  1.3959],\n",
       "        [-0.5587, -1.0031, -0.9086,  ...,  1.2048, -0.4641,  1.3008],\n",
       "        [-1.4123,  3.1108,  2.3815,  ..., -0.1452, -0.4641, -2.7933],\n",
       "        ...,\n",
       "        [-1.0110,  0.8632,  0.4577,  ...,  1.2048, -0.4641, -1.5177],\n",
       "        [ 1.4706, -1.4112, -1.6018,  ..., -0.1452,  1.9109,  0.2541],\n",
       "        [ 2.4432, -2.6194, -2.7603,  ..., -0.1452, -0.4641, -0.9532]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scratch.drug_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec3a6b2b-2022-4ca1-8471-30afcbfa3262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "INCOMP_KEYS (make sure these contain what you expected):\n",
      "_IncompatibleKeys(missing_keys=['drug_embeddings.weight'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "append_ae_layer = False\n",
    "append_layer_width = (\n",
    "    datasets[\"training\"].num_genes if append_ae_layer else None\n",
    ")\n",
    "in_out_size = (\n",
    "    model_config[\"num_genes\"]\n",
    "    if append_ae_layer\n",
    "    else datasets[\"training\"].num_genes\n",
    ")\n",
    "# idea: Reconstruct the ComPert model as pretrained (hence the \"old\" in_out_size)\n",
    "# then add the append_layer (the \"new\" in_out_size)\n",
    "\n",
    "from compert.embedding import get_chemical_representation\n",
    "embedding = get_chemical_representation(\n",
    "    smiles=canon_smiles_unique_sorted,\n",
    "    embedding_model=config[\"model\"][\"embedding\"][\"model\"],\n",
    "    data_dir=config[\"model\"][\"embedding\"][\"directory\"],\n",
    "    device=\"cuda\",\n",
    ")\n",
    "state_dict, cov_embeddings_state_dicts, model_config = load_torch_model(\"test.pt\")\n",
    "append_layer_width = (\n",
    "    config[\"dataset\"][\"n_vars\"]\n",
    "    if (config[\"model\"][\"append_ae_layer\"] and config[\"model\"][\"load_pretrained\"])\n",
    "    else None\n",
    ")\n",
    "\n",
    "if config[\"model\"][\"embedding\"][\"model\"] != \"vanilla\":\n",
    "    state_dict.pop(\"drug_embeddings.weight\")\n",
    "\n",
    "from compert.model import ComPert\n",
    "autoencoder = ComPert(\n",
    "    **model_config, drug_embeddings=embedding, append_layer_width=append_layer_width\n",
    ")\n",
    "incomp_keys = autoencoder.load_state_dict(state_dict, strict=False)\n",
    "for embedding, state_dict in zip(\n",
    "    autoencoder.covariates_embeddings, cov_embeddings_state_dicts\n",
    "):\n",
    "    embedding.load_state_dict(state_dict)\n",
    "autoencoder.eval()\n",
    "print(\n",
    "    f\"INCOMP_KEYS (make sure these contain what you expected):\\n{incomp_keys}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dfffbc1-ad9c-475a-9195-e1790a3a4d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((3,2000))\n",
    "\n",
    "(model_scratch.encoder.network[0](x) == autoencoder.encoder.network[0](x)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83d5dc79-d22a-4969-b8a1-d55b67e26088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82a833defba442a9b2338a1d748647c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCF7_CUDC-101_0.001: 0.56\n",
      "MCF7_CUDC-101_0.01: 0.55\n",
      "MCF7_CUDC-101_0.1: 0.50\n",
      "MCF7_CUDC-101_1.0: 0.24\n",
      "MCF7_CUDC-907_0.001: 0.35\n",
      "MCF7_CUDC-907_0.01: 0.33\n",
      "MCF7_CUDC-907_0.1: 0.16\n",
      "MCF7_CUDC-907_1.0: -0.39\n",
      "MCF7_Dacinostat_0.001: 0.38\n",
      "MCF7_Dacinostat_0.01: 0.27\n",
      "MCF7_Dacinostat_0.1: -0.29\n",
      "MCF7_Dacinostat_1.0: -0.41\n",
      "MCF7_Givinostat_0.001: 0.45\n",
      "MCF7_Givinostat_0.01: 0.46\n",
      "MCF7_Givinostat_0.1: 0.14\n",
      "MCF7_Givinostat_1.0: -0.49\n",
      "MCF7_Hesperadin_0.001: 0.47\n",
      "MCF7_Hesperadin_0.01: 0.48\n",
      "MCF7_Hesperadin_0.1: 0.16\n",
      "MCF7_Hesperadin_1.0: 0.39\n",
      "MCF7_Pirarubicin_0.001: 0.40\n",
      "MCF7_Pirarubicin_0.01: 0.40\n",
      "MCF7_Pirarubicin_0.1: 0.44\n",
      "MCF7_Pirarubicin_1.0: 0.32\n",
      "MCF7_Raltitrexed_0.001: 0.35\n",
      "MCF7_Raltitrexed_0.01: 0.34\n",
      "MCF7_Raltitrexed_0.1: 0.23\n",
      "MCF7_Raltitrexed_1.0: 0.25\n",
      "MCF7_Tanespimycin_0.001: 0.21\n",
      "MCF7_Tanespimycin_0.01: 0.22\n",
      "MCF7_Tanespimycin_0.1: 0.33\n",
      "MCF7_Tanespimycin_1.0: 0.22\n",
      "MCF7_Trametinib_0.001: 0.05\n",
      "MCF7_Trametinib_0.01: -0.02\n",
      "MCF7_Trametinib_0.1: 0.26\n",
      "MCF7_Trametinib_1.0: 0.29\n"
     ]
    }
   ],
   "source": [
    "drug_r2_scratch, _ = compute_pred(autoencoder,\n",
    "                                  datasets['ood'],\n",
    "                                  genes_control=datasets['test_control'].genes, \n",
    "                                  dosages=dosages) # non-pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8fc96-f034-407b-a32b-97728ea7ea6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('chemical_CPA': conda)",
   "language": "python",
   "name": "python3712jvsc74a57bd01951151eba8820d10dfca2d7d54a7baca5e102b36d5a32493b1f70139f456eae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
